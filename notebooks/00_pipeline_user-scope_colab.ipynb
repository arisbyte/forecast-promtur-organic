{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline: Forecast de Usuarios - Tráfico Orgánico\n",
    "\n",
    "**Proyecto:** Predicción de usuarios por canal orgánico 2026  \n",
    "**Modelo:** Prophet (Facebook)  \n",
    "**Última actualización:** Noviembre 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Contenido\n",
    "\n",
    "1. Configuración del entorno\n",
    "2. Análisis exploratorio\n",
    "3. Preparación de datos\n",
    "4. Modelos de forecasting\n",
    "5. Visualización y reportes\n",
    "6. Descarga de resultados\n",
    "\n",
    "---\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "### En Google Colab:\n",
    "1. Ejecuta todas las celdas (Runtime → Run all)\n",
    "2. Sube tu CSV cuando se te pida\n",
    "3. Los resultados se descargarán automáticamente al final\n",
    "\n",
    "### En entorno local:\n",
    "1. Coloca tu CSV en `data/raw/ga4_promtur_organic_users_2025.csv`\n",
    "2. Ejecuta todas las celdas secuencialmente\n",
    "3. Los resultados se guardarán en las carpetas correspondientes\n",
    "\n",
    "## Archivo CSV requerido\n",
    "\n",
    "**Nombre esperado:** `ga4_promtur_organic_users_2025.csv`\n",
    "\n",
    "**Columnas requeridas:**\n",
    "- `Year`\n",
    "- `Month`\n",
    "- `Users`\n",
    "\n",
    "**Columna opcional:**\n",
    "- `Channel` - Si no existe, el análisis se realizará para el total agregado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SECCION 0: CONFIGURACION DEL ENTORNO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección automática de entorno (Local vs Colab)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"EJECUTANDO EN GOOGLE COLAB\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 1. Instalar dependencias\n",
    "    print(\"\\nInstalando librerías necesarias...\")\n",
    "    !pip install -q prophet openpyxl\n",
    "    print(\"Librerías instaladas\")\n",
    "    \n",
    "    # 2. Crear estructura de carpetas\n",
    "    print(\"\\nCreando estructura de carpetas...\")\n",
    "    !mkdir -p data/raw data/processed data/forecasts\n",
    "    !mkdir -p results/figures/exploratory results/figures/final\n",
    "    !mkdir -p results/reports\n",
    "    print(\"Carpetas creadas\")\n",
    "    \n",
    "    # 3. Upload de archivo CSV\n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SUBIR ARCHIVO DE DATOS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nPor favor, sube tu archivo CSV con las siguientes columnas:\")\n",
    "    print(\"  Requeridas:\")\n",
    "    print(\"    - Year\")\n",
    "    print(\"    - Month\")\n",
    "    print(\"    - Users\")\n",
    "    print(\"  Opcional:\")\n",
    "    print(\"    - Channel (si no existe, se analizará el total agregado)\")\n",
    "    print(\"\\nNombre recomendado: ga4_promtur_organic_users_2025.csv\\n\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Mover CSV a data/raw/\n",
    "    for filename in uploaded.keys():\n",
    "        shutil.move(filename, 'data/raw/ga4_promtur_organic_users_2025.csv')\n",
    "        print(f\"\\nArchivo guardado como: data/raw/ga4_promtur_organic_users_2025.csv\")\n",
    "    \n",
    "    # Definir rutas para Colab\n",
    "    DATA_RAW = Path('data/raw')\n",
    "    DATA_PROCESSED = Path('data/processed')\n",
    "    DATA_FORECASTS = Path('data/forecasts')\n",
    "    RESULTS_FIGURES_EXPLORATORY = Path('results/figures/exploratory')\n",
    "    RESULTS_FIGURES_FINAL = Path('results/figures/final')\n",
    "    RESULTS_REPORTS = Path('results/reports')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CONFIGURACION DE COLAB COMPLETADA\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nProcede a ejecutar el resto del notebook\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"EJECUTANDO EN ENTORNO LOCAL\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Definir rutas para entorno local\n",
    "    DATA_RAW = Path('../data/raw')\n",
    "    DATA_PROCESSED = Path('../data/processed')\n",
    "    DATA_FORECASTS = Path('../data/forecasts')\n",
    "    RESULTS_FIGURES_EXPLORATORY = Path('../results/figures/exploratory')\n",
    "    RESULTS_FIGURES_FINAL = Path('../results/figures/final')\n",
    "    RESULTS_REPORTS = Path('../results/reports')\n",
    "    \n",
    "    # Crear carpetas si no existen\n",
    "    for folder in [DATA_RAW, DATA_PROCESSED, DATA_FORECASTS, \n",
    "                   RESULTS_FIGURES_EXPLORATORY, RESULTS_FIGURES_FINAL, \n",
    "                   RESULTS_REPORTS]:\n",
    "        folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"Entorno local configurado\")\n",
    "    print(\"\\nProcede a ejecutar el resto del notebook\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "\n",
    "# Ignorar warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuración de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SECCION 1: ANALISIS EXPLORATORIO\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Carga y exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "csv_file = DATA_RAW / 'ga4_promtur_organic_users_2025.csv'\n",
    "\n",
    "if csv_file.exists():\n",
    "    df_raw = pd.read_csv(csv_file)\n",
    "    print(f\"Dataset cargado exitosamente\")\n",
    "    print(f\"Dimensiones: {df_raw.shape[0]} filas x {df_raw.shape[1]} columnas\\n\")\n",
    "else:\n",
    "    print(f\"Error: No se encontró el archivo {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de nombres de columnas originales\n",
    "year_col = 'Year'\n",
    "month_col = 'Month'\n",
    "canal_col = 'Channel'\n",
    "users_col = 'Users'\n",
    "\n",
    "print(\"Variables de columnas configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección automática de columna de canal\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETECCION DE ESTRUCTURA DEL DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if canal_col not in df_raw.columns:\n",
    "    print(f\"\\nNo se detectó la columna '{canal_col}'.\")\n",
    "    print(\"Creando columna de canal con valor 'Total'...\")\n",
    "    df_raw[canal_col] = 'Total'\n",
    "    print(\"\\nEl análisis se realizará para el total agregado (sin separación por canales).\")\n",
    "    print(\"Resultado: 1 modelo, 1 gráfico, 1 tabla.\")\n",
    "else:\n",
    "    canales_detectados = df_raw[canal_col].nunique()\n",
    "    print(f\"\\nColumna '{canal_col}' detectada correctamente.\")\n",
    "    print(f\"Canales encontrados: {canales_detectados}\")\n",
    "    print(f\"Resultado: {canales_detectados} modelos, {canales_detectados} gráficos, {canales_detectados} tablas.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeras filas\n",
    "print(\"Primeras 10 filas del dataset:\\n\")\n",
    "display(df_raw.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información del dataset\n",
    "print(\"Información del dataset:\\n\")\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar canales y rango temporal\n",
    "print(\"Canales únicos encontrados:\\n\")\n",
    "print(df_raw[canal_col].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nRango temporal:\")\n",
    "print(f\"   Año(s): {sorted(df_raw[year_col].unique())}\")\n",
    "print(f\"   Meses: {sorted(df_raw[month_col].unique())}\")\n",
    "print(f\"   Total de meses únicos: {df_raw[[year_col, month_col]].drop_duplicates().shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Calidad de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores faltantes\n",
    "missing = df_raw.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"Valores faltantes encontrados:\\n\")\n",
    "    display(missing[missing > 0])\n",
    "else:\n",
    "    print(\"No hay valores faltantes\")\n",
    "\n",
    "# Verificar duplicados\n",
    "duplicados = df_raw.duplicated().sum()\n",
    "print(f\"\\nRegistros duplicados: {duplicados}\")\n",
    "if duplicados == 0:\n",
    "    print(\"No hay registros duplicados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Visualización exploratoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columna de fecha\n",
    "df_raw['fecha'] = pd.to_datetime(\n",
    "    df_raw[year_col].astype(str) + '-' + df_raw[month_col].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "# Gráfico: Evolución de usuarios por canal\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for canal in sorted(df_raw[canal_col].unique()):\n",
    "    data_canal = df_raw[df_raw[canal_col] == canal].sort_values('fecha')\n",
    "    ax.plot(data_canal['fecha'], data_canal[users_col], \n",
    "            marker='o', label=canal, linewidth=2, markersize=6)\n",
    "\n",
    "ax.set_xlabel('Mes', fontsize=12)\n",
    "ax.set_ylabel('Usuarios', fontsize=12)\n",
    "ax.set_title('Evolución de Usuarios por Canal (2025)', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Canal', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES_EXPLORATORY / 'users_by_channel.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Gráfico guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SECCION 2: PREPARACION DE DATOS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Transformación a snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de columnas a snake_case\n",
    "column_mapping = {\n",
    "    'Year': 'year',\n",
    "    'Month': 'month',\n",
    "    'Channel': 'channel',\n",
    "    'Users': 'users'\n",
    "}\n",
    "\n",
    "df_clean = df_raw.rename(columns=column_mapping)\n",
    "\n",
    "print(\"Columnas renombradas a snake_case\")\n",
    "print(f\"\\nColumnas del dataset limpio: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Creación de columna de fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columna de fecha para Prophet\n",
    "df_clean['ds'] = pd.to_datetime(\n",
    "    df_clean['year'].astype(str) + '-' + df_clean['month'].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "print(\"Columna de fecha 'ds' creada\")\n",
    "\n",
    "# Mostrar muestra\n",
    "print(\"\\nMuestra de datos procesados:\\n\")\n",
    "display(df_clean[['year', 'month', 'channel', 'users', 'ds']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Filtrado de canales (OPCIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración: usar todos los canales o filtrar\n",
    "usar_todos_los_canales = False\n",
    "\n",
    "if usar_todos_los_canales:\n",
    "    df_final = df_clean.copy()\n",
    "    print(f\"Usando TODOS los canales ({df_final['channel'].nunique()} canales)\")\n",
    "    print(f\"\\nCanales incluidos:\")\n",
    "    for canal in sorted(df_final['channel'].unique()):\n",
    "        print(f\"   - {canal}\")\n",
    "else:\n",
    "    # Personaliza esta lista según necesites\n",
    "    canales_incluir = [\n",
    "        'Organic Search',\n",
    "        'Direct',\n",
    "        #'Referral',\n",
    "        'Organic Social',\n",
    "        'AI Traffic',\n",
    "        'Email',\n",
    "        'Organic Video'\n",
    "        #'QR Code',\n",
    "        #'Organic Shopping'\n",
    "        # Agrega o quita canales según necesites\n",
    "    ]\n",
    "    \n",
    "    # Si existe canal 'Total', siempre incluirlo\n",
    "    if 'Total' in df_clean['channel'].unique():\n",
    "        print(\"Detectado canal 'Total' (dataset sin separación por canales).\")\n",
    "        print(\"El filtrado se omitirá y se usará el total agregado.\")\n",
    "        df_final = df_clean.copy()\n",
    "    else:\n",
    "        df_final = df_clean[df_clean['channel'].isin(canales_incluir)].copy()\n",
    "        print(f\"Filtrado aplicado: {len(canales_incluir)} canales seleccionados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Guardado de dataset limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas finales\n",
    "columnas_finales = ['year', 'month', 'channel', 'users', 'ds']\n",
    "\n",
    "df_output = df_final[columnas_finales].copy()\n",
    "df_output = df_output.sort_values(['year', 'month', 'channel']).reset_index(drop=True)\n",
    "\n",
    "# Guardar\n",
    "output_file = DATA_PROCESSED / 'dataset_users_clean.csv'\n",
    "df_output.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset limpio guardado en: {output_file}\")\n",
    "print(f\"Dimensiones: {df_output.shape[0]} filas x {df_output.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SECCION 3: MODELOS DE FORECASTING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "metrica_forecast = 'users'\n",
    "canales = sorted(df_output['channel'].unique())\n",
    "periodos_forecast = 12  # 12 meses de 2026\n",
    "\n",
    "print(f\"Configuración de forecasting:\")\n",
    "print(f\"\\n   Métrica: {metrica_forecast}\")\n",
    "print(f\"\\n   Canales: {len(canales)}\")\n",
    "for c in canales:\n",
    "    print(f\"      - {c}\")\n",
    "print(f\"\\n   Horizonte: {periodos_forecast} meses (2026)\")\n",
    "print(f\"\\n   Total de modelos: {len(canales)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Función de forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_forecast_prophet(df_canal, metrica, periodos=12):\n",
    "    \"\"\"\n",
    "    Crea forecast con Prophet\n",
    "    \"\"\"\n",
    "    # Preparar datos\n",
    "    df_prophet = df_canal[['ds', metrica]].rename(columns={metrica: 'y'})\n",
    "    \n",
    "    # Modelo\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=False,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False,\n",
    "        interval_width=0.95\n",
    "    )\n",
    "    \n",
    "    model.fit(df_prophet)\n",
    "    \n",
    "    # Predicciones\n",
    "    future = model.make_future_dataframe(periods=periodos, freq='MS')\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Métricas de evaluación\n",
    "    forecast_hist = forecast[forecast['ds'].isin(df_prophet['ds'])]\n",
    "    valores_reales = df_prophet['y'].values\n",
    "    valores_pred = forecast_hist['yhat'].values\n",
    "    \n",
    "    mae = np.mean(np.abs(valores_reales - valores_pred))\n",
    "    rmse = np.sqrt(np.mean((valores_reales - valores_pred)**2))\n",
    "    mape = np.mean(np.abs((valores_reales - valores_pred) / valores_reales)) * 100\n",
    "    \n",
    "    return model, forecast, {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
    "\n",
    "print(\"Función de forecasting creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos\n",
    "resultados_forecasts = {}\n",
    "metricas_evaluacion = {}\n",
    "\n",
    "print(\"Entrenando modelos...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, canal in enumerate(canales, 1):\n",
    "    print(f\"\\n[{i}/{len(canales)}] Canal: {canal}\")\n",
    "    \n",
    "    df_canal = df_output[df_output['channel'] == canal].sort_values('ds')\n",
    "    \n",
    "    model, forecast, metrics = crear_forecast_prophet(df_canal, metrica_forecast, periodos_forecast)\n",
    "    \n",
    "    resultados_forecasts[canal] = forecast\n",
    "    metricas_evaluacion[canal] = metrics\n",
    "    \n",
    "    print(f\"   MAE:  {metrics['MAE']:.2f}\")\n",
    "    print(f\"   RMSE: {metrics['RMSE']:.2f}\")\n",
    "    print(f\"   MAPE: {metrics['MAPE']:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Todos los modelos entrenados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Exportación de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidar predicciones 2026\n",
    "predicciones_2026 = []\n",
    "\n",
    "for canal in canales:\n",
    "    forecast = resultados_forecasts[canal]\n",
    "    forecast_2026 = forecast[forecast['ds'].dt.year == 2026][['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()\n",
    "    \n",
    "    forecast_2026['channel'] = canal\n",
    "    forecast_2026['metric'] = 'users'\n",
    "    forecast_2026['year'] = 2026\n",
    "    forecast_2026['month'] = forecast_2026['ds'].dt.month\n",
    "    \n",
    "    forecast_2026 = forecast_2026.rename(columns={\n",
    "        'yhat': 'predicted_value',\n",
    "        'yhat_lower': 'lower_bound',\n",
    "        'yhat_upper': 'upper_bound'\n",
    "    })\n",
    "    \n",
    "    predicciones_2026.append(forecast_2026)\n",
    "\n",
    "df_predicciones = pd.concat(predicciones_2026, ignore_index=True)\n",
    "df_predicciones = df_predicciones[[\n",
    "    'year', 'month', 'channel', 'metric', \n",
    "    'predicted_value', 'lower_bound', 'upper_bound', 'ds'\n",
    "]].sort_values(['channel', 'year', 'month']).reset_index(drop=True)\n",
    "\n",
    "# Guardar\n",
    "forecast_file = DATA_FORECASTS / 'forecasts_users_2026_all_channels.csv'\n",
    "df_predicciones.to_csv(forecast_file, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en: {forecast_file}\")\n",
    "print(f\"Total de predicciones: {len(df_predicciones)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SECCION 4: VISUALIZACION Y REPORTES\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Análisis de confiabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar canales poco confiables\n",
    "canales_confiabilidad = []\n",
    "\n",
    "for canal in canales:\n",
    "    df_canal_pred = df_predicciones[df_predicciones['channel'] == canal]\n",
    "    df_canal_hist = df_output[df_output['channel'] == canal]\n",
    "    \n",
    "    volumen = df_canal_hist['users'].mean()\n",
    "    \n",
    "    # Detectar valores negativos\n",
    "    negativos = (df_canal_pred['predicted_value'] < 0).sum()\n",
    "    \n",
    "    problemas = []\n",
    "    if volumen < 100:\n",
    "        problemas.append('Bajo volumen')\n",
    "    if negativos > 0:\n",
    "        problemas.append('Valores negativos')\n",
    "    \n",
    "    confiabilidad = 'BAJA' if problemas else ('MEDIA' if volumen < 1000 else 'ALTA')\n",
    "    \n",
    "    canales_confiabilidad.append({\n",
    "        'canal': canal,\n",
    "        'volumen_promedio': volumen,\n",
    "        'confiabilidad': confiabilidad,\n",
    "        'problemas': ', '.join(problemas) if problemas else 'Ninguno'\n",
    "    })\n",
    "\n",
    "df_confiabilidad = pd.DataFrame(canales_confiabilidad).sort_values('volumen_promedio', ascending=False)\n",
    "\n",
    "print(\"Análisis de confiabilidad:\\n\")\n",
    "display(df_confiabilidad)\n",
    "\n",
    "# Guardar\n",
    "df_confiabilidad.to_csv(RESULTS_REPORTS / 'canales_users_confiabilidad.csv', index=False)\n",
    "print(f\"\\nAnálisis guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Tablas resumen por canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tablas resumen (meses × valores)\n",
    "def crear_tabla_resumen(canal):\n",
    "    df_canal = df_predicciones[df_predicciones['channel'] == canal].copy()\n",
    "    df_canal['mes'] = df_canal['ds'].dt.strftime('%b-%y')\n",
    "    \n",
    "    tabla = df_canal.pivot(index='metric', columns='mes', values='predicted_value')\n",
    "    \n",
    "    meses_orden = df_canal.sort_values('ds')['mes'].unique()\n",
    "    tabla = tabla[meses_orden]\n",
    "    tabla['Promedio'] = tabla.mean(axis=1)\n",
    "    \n",
    "    nombres = {'users': 'Usuarios'}\n",
    "    tabla = tabla.rename(index=nombres)\n",
    "    \n",
    "    return tabla.round(2)\n",
    "\n",
    "# Generar y mostrar tablas\n",
    "print(\"TABLAS RESUMEN POR CANAL\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tablas = {}\n",
    "for canal in canales:\n",
    "    print(f\"\\nCanal: {canal}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    conf = df_confiabilidad[df_confiabilidad['canal'] == canal]['confiabilidad'].values[0]\n",
    "    if conf == 'BAJA':\n",
    "        print(\"ADVERTENCIA: Confiabilidad BAJA\\n\")\n",
    "    \n",
    "    tabla = crear_tabla_resumen(canal)\n",
    "    tablas[canal] = tabla\n",
    "    display(tabla)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tablas a Excel\n",
    "excel_file = RESULTS_REPORTS / 'tablas_resumen_users_2026.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "    for canal, tabla in tablas.items():\n",
    "        sheet_name = canal[:31]\n",
    "        tabla.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "print(f\"Tablas exportadas a: {excel_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Gráficos comparativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar gráficos para todos los canales\n",
    "print(\"Generando gráficos comparativos...\\n\")\n",
    "\n",
    "graficos_generados = 0\n",
    "\n",
    "for canal in canales:\n",
    "    print(f\"Canal: {canal}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Histórico\n",
    "    df_hist = df_output[df_output['channel'] == canal].sort_values('ds')\n",
    "    ax.plot(df_hist['ds'], df_hist['users'], \n",
    "            'o-', color='black', label='Histórico 2025', linewidth=2.5, markersize=7)\n",
    "    \n",
    "    # Predicción\n",
    "    df_pred = df_predicciones[df_predicciones['channel'] == canal].sort_values('ds')\n",
    "    \n",
    "    conf = df_confiabilidad[df_confiabilidad['canal'] == canal]['confiabilidad'].values[0]\n",
    "    color = '#0072B2' if conf in ['ALTA', 'MEDIA'] else '#D55E00'\n",
    "    linestyle = '-' if conf in ['ALTA', 'MEDIA'] else '--'\n",
    "    \n",
    "    ax.plot(df_pred['ds'], df_pred['predicted_value'], \n",
    "            'o-', color=color, label=f'Predicción 2026 ({conf})', \n",
    "            linewidth=2.5, markersize=7, linestyle=linestyle)\n",
    "    \n",
    "    ax.fill_between(df_pred['ds'], df_pred['lower_bound'], df_pred['upper_bound'],\n",
    "                    alpha=0.2, color=color, label='Intervalo 95%')\n",
    "    \n",
    "    # Línea separadora\n",
    "    fecha_sep = df_hist['ds'].max() + pd.DateOffset(days=15)\n",
    "    ax.axvline(x=fecha_sep, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    # Advertencia si baja confiabilidad\n",
    "    if conf == 'BAJA':\n",
    "        problemas = df_confiabilidad[df_confiabilidad['canal'] == canal]['problemas'].values[0]\n",
    "        ax.text(0.5, 0.95, f'ADVERTENCIA: {problemas}', \n",
    "                transform=ax.transAxes, fontsize=10, color='red',\n",
    "                ha='center', va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    ax.set_title(f'Usuarios - {canal}\\nHistórico 2025 vs Predicción 2026', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Fecha', fontsize=12)\n",
    "    ax.set_ylabel('Usuarios', fontsize=12)\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"comp_users_{canal.replace(' ', '_').lower()}.png\"\n",
    "    plt.savefig(RESULTS_FIGURES_FINAL / filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    graficos_generados += 1\n",
    "\n",
    "print(f\"\\n{graficos_generados} gráficos generados y guardados\")\n",
    "print(f\"Ubicación: {RESULTS_FIGURES_FINAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Resumen ejecutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen ejecutivo final\n",
    "print(\"=\" * 80)\n",
    "print(\"RESUMEN EJECUTIVO - PREDICCIONES USUARIOS 2026\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nPREDICCIONES POR CANAL:\\n\")\n",
    "\n",
    "for canal in sorted(canales):\n",
    "    conf = df_confiabilidad[df_confiabilidad['canal'] == canal]['confiabilidad'].values[0]\n",
    "    \n",
    "    print(f\"\\n{canal} (Confiabilidad: {conf})\")\n",
    "    \n",
    "    df_canal = df_predicciones[df_predicciones['channel'] == canal]\n",
    "    users_promedio = df_canal['predicted_value'].mean()\n",
    "    \n",
    "    print(f\"   Usuarios promedio mensual: {users_promedio:,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nANALISIS COMPLETADO\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SECCION 5: DESCARGA DE RESULTADOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    import zipfile\n",
    "    import os\n",
    "    \n",
    "    print(\"Preparando archivos para descarga...\\n\")\n",
    "    \n",
    "    # Crear ZIP con todos los resultados\n",
    "    zip_filename = 'resultados_forecast_users_promtur.zip'\n",
    "    \n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        # Agregar CSVs\n",
    "        for file in ['data/processed/dataset_users_clean.csv', \n",
    "                     'data/forecasts/forecasts_users_2026_all_channels.csv',\n",
    "                     'results/reports/canales_users_confiabilidad.csv']:\n",
    "            if os.path.exists(file):\n",
    "                zipf.write(file)\n",
    "        \n",
    "        # Agregar Excel\n",
    "        if os.path.exists('results/reports/tablas_resumen_users_2026.xlsx'):\n",
    "            zipf.write('results/reports/tablas_resumen_users_2026.xlsx')\n",
    "        \n",
    "        # Agregar gráficos\n",
    "        for root, dirs, files_list in os.walk('results/figures'):\n",
    "            for file in files_list:\n",
    "                if file.endswith('.png'):\n",
    "                    filepath = os.path.join(root, file)\n",
    "                    zipf.write(filepath)\n",
    "    \n",
    "    print(f\"Archivo ZIP creado: {zip_filename}\")\n",
    "    print(f\"Total de gráficos incluidos: {graficos_generados}\")\n",
    "    print(\"\\nDescargando resultados...\\n\")\n",
    "    \n",
    "    files.download(zip_filename)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DESCARGA COMPLETADA\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nEl archivo ZIP contiene:\")\n",
    "    print(\"  - Dataset limpio (CSV)\")\n",
    "    print(\"  - Predicciones 2026 (CSV)\")\n",
    "    print(\"  - Tablas resumen por canal (Excel)\")\n",
    "    print(\"  - Análisis de confiabilidad (CSV)\")\n",
    "    print(f\"  - {graficos_generados} gráficos comparativos (PNG)\")\n",
    "else:\n",
    "    print(\"Entorno local: Todos los archivos están guardados en sus carpetas correspondientes\")\n",
    "    print(f\"\\nTotal de gráficos generados: {graficos_generados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ANALISIS COMPLETADO\n",
    "\n",
    "### Archivos generados\n",
    "\n",
    "**Datos:**\n",
    "- `dataset_users_clean.csv` - Dataset limpio\n",
    "- `forecasts_users_2026_all_channels.csv` - Predicciones 2026\n",
    "\n",
    "**Reportes:**\n",
    "- `tablas_resumen_users_2026.xlsx` - Tablas por canal\n",
    "- `canales_users_confiabilidad.csv` - Análisis de confiabilidad\n",
    "\n",
    "**Visualizaciones:**\n",
    "- Gráficos comparativos por canal\n",
    "\n",
    "---\n",
    "\n",
    "### Consideraciones\n",
    "\n",
    "1. **Confiabilidad**: Revisar análisis de confiabilidad por canal\n",
    "2. **Intervalos de confianza**: Considerar rangos en planificación\n",
    "3. **Actualización**: Reentrenar modelos con datos reales de 2026\n",
    "\n",
    "---\n",
    "\n",
    "**Proyecto:** Forecast Promtur  \n",
    "**Fecha:** Noviembre 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
