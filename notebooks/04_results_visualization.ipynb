{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Visualizaci√≥n y An√°lisis de Resultados\n",
    "\n",
    "**Proyecto:** Forecast Promtur - Tr√°fico Org√°nico  \n",
    "**Objetivo:** Analizar, visualizar y generar reportes finales de las predicciones 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Contenido:\n",
    "1. Carga de predicciones\n",
    "2. Ajustes y limitaciones (bounce_rate 0-100%)\n",
    "3. Identificaci√≥n de canales poco confiables\n",
    "4. Tablas resumen por canal (m√©tricas √ó meses)\n",
    "5. Comparativa hist√≥rico vs predicci√≥n\n",
    "6. Visualizaciones con advertencias de incertidumbre\n",
    "7. Exportaci√≥n de reportes finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n inicial y librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Ignorar warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuraci√≥n de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n auxiliar para formatear duraci√≥n (reutilizada del Notebook 02)\n",
    "def segundos_a_hhmm_ss(segundos):\n",
    "    \"\"\"\n",
    "    Convierte segundos a formato HH:MM:SS\n",
    "    \"\"\"\n",
    "    if pd.isna(segundos) or segundos < 0:\n",
    "        return \"00:00:00\"\n",
    "    \n",
    "    horas = int(segundos // 3600)\n",
    "    minutos = int((segundos % 3600) // 60)\n",
    "    segs = int(segundos % 60)\n",
    "    \n",
    "    return f\"{horas:02d}:{minutos:02d}:{segs:02d}\"\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de formateo creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rutas\n",
    "DATA_PROCESSED = Path('../data/processed')\n",
    "DATA_FORECASTS = Path('../data/forecasts')\n",
    "RESULTS_FIGURES = Path('../results/figures/final')\n",
    "RESULTS_REPORTS = Path('../results/reports')\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "RESULTS_FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar dataset hist√≥rico\n",
    "df_historico = pd.read_csv(DATA_PROCESSED / 'dataset_clean.csv')\n",
    "df_historico['ds'] = pd.to_datetime(\n",
    "    df_historico['year'].astype(str) + '-' + df_historico['month'].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "# Cargar predicciones\n",
    "df_predicciones = pd.read_csv(DATA_FORECASTS / 'forecasts_2026_all_channels.csv')\n",
    "df_predicciones['ds'] = pd.to_datetime(df_predicciones['ds'])\n",
    "\n",
    "print(\"‚úÖ Datos cargados exitosamente\")\n",
    "print(f\"\\nüìä Datos hist√≥ricos: {df_historico.shape[0]} filas\")\n",
    "print(f\"üìä Predicciones 2026: {df_predicciones.shape[0]} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajustes cr√≠ticos: Limitaci√≥n de bounce_rate\n",
    "\n",
    "**IMPORTANTE:** El bounce_rate debe estar entre 0% y 100%. Prophet puede predecir valores fuera de este rango, as√≠ que los limitaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar predicciones de bounce_rate fuera del rango 0-100%\n",
    "bounce_predictions = df_predicciones[df_predicciones['metric'] == 'bounce_rate'].copy()\n",
    "\n",
    "print(\"üîç An√°lisis de bounce_rate ANTES de limitar:\\n\")\n",
    "print(f\"Total de predicciones: {len(bounce_predictions)}\")\n",
    "print(f\"Valores < 0%: {(bounce_predictions['predicted_value'] < 0).sum()}\")\n",
    "print(f\"Valores > 100%: {(bounce_predictions['predicted_value'] > 100).sum()}\")\n",
    "print(f\"\\nRango actual: [{bounce_predictions['predicted_value'].min():.2f}% , {bounce_predictions['predicted_value'].max():.2f}%]\")\n",
    "\n",
    "if (bounce_predictions['predicted_value'] < 0).sum() > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Canales con bounce_rate negativo:\")\n",
    "    negativos = bounce_predictions[bounce_predictions['predicted_value'] < 0]\n",
    "    for canal in negativos['channel'].unique():\n",
    "        print(f\"   - {canal}\")\n",
    "\n",
    "if (bounce_predictions['predicted_value'] > 100).sum() > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Canales con bounce_rate > 100%:\")\n",
    "    altos = bounce_predictions[bounce_predictions['predicted_value'] > 100]\n",
    "    for canal in altos['channel'].unique():\n",
    "        print(f\"   - {canal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limitaci√≥n: 0% <= bounce_rate <= 100%\n",
    "print(\"\\nüîß Aplicando limitaci√≥n de bounce_rate...\\n\")\n",
    "\n",
    "# Crear m√°scara para bounce_rate\n",
    "mask_bounce = df_predicciones['metric'] == 'bounce_rate'\n",
    "\n",
    "# Limitar predicted_value\n",
    "df_predicciones.loc[mask_bounce, 'predicted_value'] = df_predicciones.loc[mask_bounce, 'predicted_value'].clip(0, 100)\n",
    "\n",
    "# Limitar lower_bound (m√≠nimo 0%)\n",
    "df_predicciones.loc[mask_bounce, 'lower_bound'] = df_predicciones.loc[mask_bounce, 'lower_bound'].clip(0, 100)\n",
    "\n",
    "# Limitar upper_bound (m√°ximo 100%)\n",
    "df_predicciones.loc[mask_bounce, 'upper_bound'] = df_predicciones.loc[mask_bounce, 'upper_bound'].clip(0, 100)\n",
    "\n",
    "print(\"‚úÖ Bounce_rate limitado a rango 0-100%\")\n",
    "print(f\"\\nRango despu√©s de limitar: [0.00% , {df_predicciones[mask_bounce]['predicted_value'].max():.2f}%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identificaci√≥n de canales poco confiables\n",
    "\n",
    "Identificaremos canales con predicciones poco confiables bas√°ndonos en:\n",
    "- Valores negativos en m√©tricas que no pueden ser negativas\n",
    "- Intervalos de confianza muy amplios\n",
    "- Bajo volumen hist√≥rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular indicadores de confiabilidad por canal\n",
    "canales_confiabilidad = []\n",
    "\n",
    "for canal in df_predicciones['channel'].unique():\n",
    "    # Filtrar datos del canal\n",
    "    df_canal_pred = df_predicciones[df_predicciones['channel'] == canal]\n",
    "    df_canal_hist = df_historico[df_historico['channel'] == canal]\n",
    "    \n",
    "    # 1. Volumen hist√≥rico promedio de sesiones\n",
    "    volumen_promedio = df_canal_hist['sessions'].mean()\n",
    "    \n",
    "    # 2. Detectar valores negativos en m√©tricas que no pueden ser negativas\n",
    "    metricas_positivas = ['sessions', 'views_per_session', 'avg_session_duration']\n",
    "    valores_negativos = df_canal_pred[\n",
    "        df_canal_pred['metric'].isin(metricas_positivas) & \n",
    "        (df_canal_pred['predicted_value'] < 0)\n",
    "    ].shape[0]\n",
    "    \n",
    "    # 3. Calcular amplitud promedio de intervalos de confianza (relativo al valor predicho)\n",
    "    df_canal_pred['intervalo_amplitud'] = (\n",
    "        (df_canal_pred['upper_bound'] - df_canal_pred['lower_bound']) / \n",
    "        df_canal_pred['predicted_value'].abs().replace(0, 1)\n",
    "    ) * 100\n",
    "    amplitud_promedio = df_canal_pred['intervalo_amplitud'].mean()\n",
    "    \n",
    "    # Clasificar confiabilidad\n",
    "    problemas = []\n",
    "    if volumen_promedio < 100:\n",
    "        problemas.append('Bajo volumen hist√≥rico')\n",
    "    if valores_negativos > 0:\n",
    "        problemas.append('Valores negativos predichos')\n",
    "    if amplitud_promedio > 200:  # Intervalo > 200% del valor predicho\n",
    "        problemas.append('Alta incertidumbre')\n",
    "    \n",
    "    confiabilidad = 'BAJA' if problemas else ('MEDIA' if volumen_promedio < 1000 else 'ALTA')\n",
    "    \n",
    "    canales_confiabilidad.append({\n",
    "        'canal': canal,\n",
    "        'volumen_promedio_historico': volumen_promedio,\n",
    "        'valores_negativos': valores_negativos,\n",
    "        'amplitud_intervalo_promedio_%': amplitud_promedio,\n",
    "        'confiabilidad': confiabilidad,\n",
    "        'problemas': ', '.join(problemas) if problemas else 'Ninguno'\n",
    "    })\n",
    "\n",
    "df_confiabilidad = pd.DataFrame(canales_confiabilidad)\n",
    "df_confiabilidad = df_confiabilidad.sort_values('volumen_promedio_historico', ascending=False)\n",
    "\n",
    "print(\"üìä An√°lisis de confiabilidad de predicciones por canal:\\n\")\n",
    "display(df_confiabilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar an√°lisis de confiabilidad\n",
    "confiabilidad_file = RESULTS_REPORTS / 'canales_confiabilidad.csv'\n",
    "df_confiabilidad.to_csv(confiabilidad_file, index=False)\n",
    "print(f\"üíæ An√°lisis de confiabilidad guardado en: {confiabilidad_file}\")\n",
    "\n",
    "# Resumen de confiabilidad\n",
    "print(\"\\nüìà Resumen de confiabilidad:\\n\")\n",
    "print(df_confiabilidad['confiabilidad'].value_counts())\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Canales con confiabilidad BAJA:\")\n",
    "canales_baja = df_confiabilidad[df_confiabilidad['confiabilidad'] == 'BAJA']\n",
    "if len(canales_baja) > 0:\n",
    "    for _, row in canales_baja.iterrows():\n",
    "        print(f\"   - {row['canal']}: {row['problemas']}\")\n",
    "else:\n",
    "    print(\"   (Ninguno)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tablas resumen por canal\n",
    "\n",
    "Generaremos una tabla para cada canal con **m√©tricas en filas** y **meses en columnas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_tabla_resumen_canal(df_pred, canal):\n",
    "    \"\"\"\n",
    "    Crea una tabla resumen para un canal espec√≠fico.\n",
    "    Formato: M√©tricas en filas, meses en columnas\n",
    "    \"\"\"\n",
    "    # Filtrar predicciones del canal\n",
    "    df_canal = df_pred[df_pred['channel'] == canal].copy()\n",
    "    \n",
    "    # Crear columna de mes en formato legible\n",
    "    df_canal['mes_nombre'] = df_canal['ds'].dt.strftime('%b-%y')\n",
    "    \n",
    "    # Pivot: m√©tricas en filas, meses en columnas\n",
    "    tabla = df_canal.pivot(\n",
    "        index='metric',\n",
    "        columns='mes_nombre',\n",
    "        values='predicted_value'\n",
    "    )\n",
    "    \n",
    "    # Reordenar columnas cronol√≥gicamente\n",
    "    meses_ordenados = df_canal.sort_values('ds')['mes_nombre'].unique()\n",
    "    tabla = tabla[meses_ordenados]\n",
    "    \n",
    "    # Agregar columna de promedio\n",
    "    tabla['Promedio 2026'] = tabla.mean(axis=1)\n",
    "    \n",
    "    # Renombrar √≠ndice para nombres legibles\n",
    "    nombres_metricas = {\n",
    "        'sessions': 'Sesiones',\n",
    "        'bounce_rate': 'Bounce Rate (%)',\n",
    "        'views_per_session': 'Vistas/Sesi√≥n',\n",
    "        'avg_session_duration': 'Duraci√≥n Avg (seg)'\n",
    "    }\n",
    "    tabla = tabla.rename(index=nombres_metricas)\n",
    "    \n",
    "    return tabla.round(2)\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de tabla resumen creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar tablas para todos los canales\n",
    "print(\"üìä Generando tablas resumen por canal...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tablas_canales = {}\n",
    "\n",
    "for canal in sorted(df_predicciones['channel'].unique()):\n",
    "    print(f\"\\nüìà Canal: {canal}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Obtener confiabilidad del canal\n",
    "    confiabilidad = df_confiabilidad[df_confiabilidad['canal'] == canal]['confiabilidad'].values[0]\n",
    "    \n",
    "    if confiabilidad == 'BAJA':\n",
    "        problemas = df_confiabilidad[df_confiabilidad['canal'] == canal]['problemas'].values[0]\n",
    "        print(f\"‚ö†Ô∏è ADVERTENCIA: Confiabilidad BAJA - {problemas}\\n\")\n",
    "    \n",
    "    # Crear tabla\n",
    "    tabla = crear_tabla_resumen_canal(df_predicciones, canal)\n",
    "    tablas_canales[canal] = tabla\n",
    "    \n",
    "    display(tabla)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ {len(tablas_canales)} tablas resumen generadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tablas a Excel (una hoja por canal)\n",
    "excel_file = RESULTS_REPORTS / 'tablas_resumen_por_canal_2026.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "    for canal, tabla in tablas_canales.items():\n",
    "        # Limpiar nombre para usar como nombre de hoja (max 31 caracteres)\n",
    "        sheet_name = canal[:31]\n",
    "        tabla.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "print(f\"üíæ Tablas exportadas a Excel: {excel_file}\")\n",
    "print(f\"üìä {len(tablas_canales)} hojas creadas (una por canal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparativa hist√≥rico vs predicci√≥n\n",
    "\n",
    "Visualizaremos la evoluci√≥n hist√≥rica (2025) y las predicciones (2026) para todos los canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_historico_vs_prediccion(df_hist, df_pred, canal, metrica, titulo):\n",
    "    \"\"\"\n",
    "    Grafica hist√≥rico vs predicci√≥n con advertencias de confiabilidad\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Filtrar datos\n",
    "    df_canal_hist = df_hist[df_hist['channel'] == canal].sort_values('ds')\n",
    "    df_canal_pred = df_pred[(df_pred['channel'] == canal) & (df_pred['metric'] == metrica)].sort_values('ds')\n",
    "    \n",
    "    # Obtener confiabilidad\n",
    "    confiabilidad = df_confiabilidad[df_confiabilidad['canal'] == canal]['confiabilidad'].values[0]\n",
    "    \n",
    "    # Datos hist√≥ricos\n",
    "    ax.plot(df_canal_hist['ds'], df_canal_hist[metrica], \n",
    "            'o-', color='black', label='Hist√≥rico 2025', linewidth=2.5, markersize=7)\n",
    "    \n",
    "    # Predicciones\n",
    "    color_pred = '#0072B2' if confiabilidad in ['ALTA', 'MEDIA'] else '#D55E00'  # Naranja si baja confiabilidad\n",
    "    linestyle_pred = '-' if confiabilidad in ['ALTA', 'MEDIA'] else '--'\n",
    "    \n",
    "    ax.plot(df_canal_pred['ds'], df_canal_pred['predicted_value'], \n",
    "            'o-', color=color_pred, label=f'Predicci√≥n 2026 (Confiabilidad: {confiabilidad})', \n",
    "            linewidth=2.5, markersize=7, linestyle=linestyle_pred)\n",
    "    \n",
    "    # Intervalo de confianza\n",
    "    ax.fill_between(df_canal_pred['ds'], \n",
    "                     df_canal_pred['lower_bound'], \n",
    "                     df_canal_pred['upper_bound'],\n",
    "                     alpha=0.2, color=color_pred, label='Intervalo de confianza (95%)')\n",
    "    \n",
    "    # L√≠nea vertical separando hist√≥rico de predicci√≥n\n",
    "    fecha_separacion = df_canal_hist['ds'].max() + pd.DateOffset(days=15)\n",
    "    ax.axvline(x=fecha_separacion, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    # Advertencia si confiabilidad baja\n",
    "    if confiabilidad == 'BAJA':\n",
    "        problemas = df_confiabilidad[df_confiabilidad['canal'] == canal]['problemas'].values[0]\n",
    "        ax.text(0.5, 0.95, f'‚ö†Ô∏è ADVERTENCIA: {problemas}', \n",
    "                transform=ax.transAxes, fontsize=10, color='red',\n",
    "                ha='center', va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    ax.set_xlabel('Fecha', fontsize=12)\n",
    "    ax.set_ylabel(titulo, fontsize=12)\n",
    "    ax.set_title(f'{titulo} - {canal}\\nHist√≥rico 2025 vs Predicci√≥n 2026', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar gr√°fico\n",
    "    filename = f\"comparativa_{metrica}_{canal.replace(' ', '_').lower()}.png\"\n",
    "    plt.savefig(RESULTS_FIGURES / filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de comparativa creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar gr√°ficos comparativos para todos los canales y m√©tricas\n",
    "print(\"üìä Generando gr√°ficos comparativos hist√≥rico vs predicci√≥n...\\n\")\n",
    "\n",
    "metricas_titulos = {\n",
    "    'sessions': 'Sesiones',\n",
    "    'bounce_rate': 'Bounce Rate (%)',\n",
    "    'views_per_session': 'Vistas por Sesi√≥n',\n",
    "    'avg_session_duration': 'Duraci√≥n Promedio (segundos)'\n",
    "}\n",
    "\n",
    "graficos_comparativos = []\n",
    "canales = sorted(df_predicciones['channel'].unique())\n",
    "\n",
    "for canal in canales:\n",
    "    print(f\"\\nüìà Canal: {canal}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for metrica, titulo in metricas_titulos.items():\n",
    "        print(f\"   Gr√°fico: {titulo}\")\n",
    "        filename = plot_historico_vs_prediccion(\n",
    "            df_historico, df_predicciones, canal, metrica, titulo\n",
    "        )\n",
    "        graficos_comparativos.append(filename)\n",
    "\n",
    "print(f\"\\n‚úÖ {len(graficos_comparativos)} gr√°ficos comparativos generados\")\n",
    "print(f\"üìÅ Ubicaci√≥n: {RESULTS_FIGURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dashboard consolidado por m√©trica\n",
    "\n",
    "Un gr√°fico por m√©trica mostrando TODOS los canales juntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dashboard_metrica(df_hist, df_pred, metrica, titulo):\n",
    "    \"\"\"\n",
    "    Dashboard consolidado: todos los canales para una m√©trica\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    canales = sorted(df_pred['channel'].unique())\n",
    "    colores = plt.cm.tab10(np.linspace(0, 1, len(canales)))\n",
    "    \n",
    "    for i, canal in enumerate(canales):\n",
    "        # Hist√≥rico\n",
    "        df_canal_hist = df_hist[df_hist['channel'] == canal].sort_values('ds')\n",
    "        ax.plot(df_canal_hist['ds'], df_canal_hist[metrica], \n",
    "                'o-', color=colores[i], label=f'{canal}', \n",
    "                linewidth=2, markersize=5, alpha=0.7)\n",
    "        \n",
    "        # Predicci√≥n\n",
    "        df_canal_pred = df_pred[(df_pred['channel'] == canal) & (df_pred['metric'] == metrica)].sort_values('ds')\n",
    "        \n",
    "        # Verificar confiabilidad\n",
    "        confiabilidad = df_confiabilidad[df_confiabilidad['canal'] == canal]['confiabilidad'].values[0]\n",
    "        linestyle = '-' if confiabilidad in ['ALTA', 'MEDIA'] else '--'\n",
    "        \n",
    "        ax.plot(df_canal_pred['ds'], df_canal_pred['predicted_value'], \n",
    "                'o-', color=colores[i], linewidth=2, markersize=5, \n",
    "                linestyle=linestyle, alpha=0.7)\n",
    "    \n",
    "    # L√≠nea vertical separando hist√≥rico de predicci√≥n\n",
    "    fecha_separacion = df_hist['ds'].max() + pd.DateOffset(days=15)\n",
    "    ax.axvline(x=fecha_separacion, color='gray', linestyle=':', linewidth=2, alpha=0.7, \n",
    "               label='Inicio predicci√≥n 2026')\n",
    "    \n",
    "    ax.set_xlabel('Fecha', fontsize=12)\n",
    "    ax.set_ylabel(titulo, fontsize=12)\n",
    "    ax.set_title(f'Dashboard: {titulo}\\nTodos los Canales - Hist√≥rico 2025 vs Predicci√≥n 2026', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar\n",
    "    filename = f\"dashboard_{metrica}_all_channels.png\"\n",
    "    plt.savefig(RESULTS_FIGURES / filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de dashboard creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dashboards consolidados\n",
    "print(\"üìä Generando dashboards consolidados por m√©trica...\\n\")\n",
    "\n",
    "dashboards = []\n",
    "\n",
    "for metrica, titulo in metricas_titulos.items():\n",
    "    print(f\"Dashboard: {titulo}\")\n",
    "    filename = plot_dashboard_metrica(df_historico, df_predicciones, metrica, titulo)\n",
    "    dashboards.append(filename)\n",
    "\n",
    "print(f\"\\n‚úÖ {len(dashboards)} dashboards consolidados generados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen ejecutivo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear resumen ejecutivo con totales\n",
    "print(\"=\"*80)\n",
    "print(\"üéØ RESUMEN EJECUTIVO FINAL - PREDICCIONES 2026\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. PREDICCIONES POR CANAL:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for canal in sorted(df_predicciones['channel'].unique()):\n",
    "    confiabilidad = df_confiabilidad[df_confiabilidad['canal'] == canal]['confiabilidad'].values[0]\n",
    "    icono = '‚úÖ' if confiabilidad == 'ALTA' else ('‚ö†Ô∏è' if confiabilidad == 'MEDIA' else 'üö®')\n",
    "    \n",
    "    print(f\"\\n{icono} {canal} (Confiabilidad: {confiabilidad})\")\n",
    "    \n",
    "    df_canal = df_predicciones[df_predicciones['channel'] == canal]\n",
    "    \n",
    "    # Sesiones\n",
    "    sessions = df_canal[df_canal['metric'] == 'sessions']\n",
    "    total_sessions = sessions['predicted_value'].sum()\n",
    "    print(f\"   - Sesiones 2026 (total): {total_sessions:,.0f}\")\n",
    "    \n",
    "    # Bounce rate\n",
    "    bounce = df_canal[df_canal['metric'] == 'bounce_rate']['predicted_value'].mean()\n",
    "    print(f\"   - Bounce Rate (promedio): {bounce:.1f}%\")\n",
    "    \n",
    "    # Vistas por sesi√≥n\n",
    "    vps = df_canal[df_canal['metric'] == 'views_per_session']['predicted_value'].mean()\n",
    "    print(f\"   - Vistas/Sesi√≥n (promedio): {vps:.2f}\")\n",
    "    \n",
    "    # Duraci√≥n\n",
    "    dur = df_canal[df_canal['metric'] == 'avg_session_duration']['predicted_value'].mean()\n",
    "    print(f\"   - Duraci√≥n promedio: {segundos_a_hhmm_ss(dur)} ({dur:.0f} seg)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n2. CANALES POR CONFIABILIDAD:\")\n",
    "print(\"-\" * 80)\n",
    "for nivel in ['ALTA', 'MEDIA', 'BAJA']:\n",
    "    canales_nivel = df_confiabilidad[df_confiabilidad['confiabilidad'] == nivel]['canal'].tolist()\n",
    "    if canales_nivel:\n",
    "        print(f\"\\n{nivel}: {', '.join(canales_nivel)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n3. ARCHIVOS GENERADOS:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nüìä Tablas resumen: {excel_file.name}\")\n",
    "print(f\"üìà Gr√°ficos comparativos: {len(graficos_comparativos)} archivos\")\n",
    "print(f\"üìä Dashboards consolidados: {len(dashboards)} archivos\")\n",
    "print(f\"üìã An√°lisis de confiabilidad: {confiabilidad_file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n4. RECOMENDACIONES:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\n‚úÖ Usar con confianza:\")\n",
    "print(\"   - Predicciones de canales con confiabilidad ALTA\")\n",
    "print(\"   - Enfocarse en Organic Search, Direct y Referral\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Usar con precauci√≥n:\")\n",
    "print(\"   - Predicciones de canales con confiabilidad MEDIA\")\n",
    "print(\"   - Considerar rangos de intervalo de confianza\")\n",
    "\n",
    "print(\"\\nüö® NO usar para decisiones estrat√©gicas:\")\n",
    "print(\"   - Predicciones de canales con confiabilidad BAJA\")\n",
    "canales_baja = df_confiabilidad[df_confiabilidad['confiabilidad'] == 'BAJA']['canal'].tolist()\n",
    "if canales_baja:\n",
    "    print(f\"   - Canales: {', '.join(canales_baja)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úÖ AN√ÅLISIS COMPLETADO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notas finales:\n",
    "\n",
    "### Ajustes aplicados:\n",
    "- **Bounce Rate limitado**: 0% - 100% (valores fuera de rango fueron ajustados)\n",
    "- **Canales se√±alizados**: Se identificaron canales con baja confiabilidad\n",
    "- **Advertencias visuales**: Gr√°ficos muestran alertas para predicciones inciertas\n",
    "\n",
    "### Archivos generados:\n",
    "1. `tablas_resumen_por_canal_2026.xlsx` - Una hoja por canal con m√©tricas √ó meses\n",
    "2. `canales_confiabilidad.csv` - An√°lisis de confiabilidad de predicciones\n",
    "3. Gr√°ficos comparativos individuales (hist√≥rico vs predicci√≥n)\n",
    "4. Dashboards consolidados por m√©trica\n",
    "\n",
    "### ‚ö†Ô∏è Consideraciones importantes:\n",
    "\n",
    "1. **Bounce Rate > 100%**: Limitado autom√°ticamente, pero indica alta incertidumbre\n",
    "2. **Valores negativos**: Se√±alizados como predicciones poco confiables\n",
    "3. **Intervalos amplios**: Indican baja confianza del modelo\n",
    "4. **Bajo volumen hist√≥rico**: Solo 11 meses limitan precisi√≥n\n",
    "\n",
    "### Recomendaciones de uso:\n",
    "\n",
    "- **Planificaci√≥n estrat√©gica**: Usar solo canales con confiabilidad ALTA\n",
    "- **Presupuestos**: Considerar rangos de intervalo de confianza\n",
    "- **Decisiones t√°cticas**: Canales MEDIA pueden usarse con precauci√≥n\n",
    "- **Monitoreo continuo**: Actualizar modelos con datos reales de 2026\n",
    "\n",
    "## Pr√≥ximos pasos sugeridos:\n",
    "\n",
    "1. Incorporar datos de 2024 cuando est√©n disponibles\n",
    "2. Agregar columna de 'users' al an√°lisis\n",
    "3. Reentrenar modelos trimestralmente\n",
    "4. Adaptar a Google Colab para uso compartido"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
